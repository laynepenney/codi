version: '1'
models:
  haiku:
    provider: anthropic
    model: claude-3-5-haiku-latest
    description: Fast, cheap model for quick tasks
  sonnet:
    provider: anthropic
    model: claude-sonnet-4-20250514
    description: Balanced model for coding tasks
  opus:
    provider: anthropic
    model: claude-opus-4-20250514
    description: Most capable for complex reasoning
  llama3:
    provider: ollama-native
    model: llama3.2
    description: Free local model
  coder:
    provider: ollama-native
    model: qwen3-coder:480b-cloud
    description: Cloud coder
  gpt-5-nano:
    provider: openai
    model: gpt-5-nano
    description: Fast, cheap GPT-5 model
  gpt-5:
    provider: openai
    model: gpt-5.2
    description: Latest GPT-5, best for coding
  qwen3-lite:
    provider: ollama-native
    model: qwen3:8b
    description: qwen lite
  gemini-3-flash-preview:
    provider: ollama-native
    model: gemini-3-flash-preview:cloud
    description: gemini cloud fast
  gpt-oss:
    provider: ollama-native
    model: gpt-oss:120b-cloud
    description: cloud gpt oss 120b-cloud
tasks:
  fast:
    model: haiku
    description: Quick tasks (commits, summaries)
  code:
    model: coder
    description: Standard coding tasks
  complex:
    model: gpt-5
    description: Architecture, debugging
  summarize:
    model: llama3
    description: Context summarization
  document:
    model: qwen3-lite
commands:
  commit:
    task: fast
  fix:
    task: complex
fallbacks:
  primary:
    - coder
    - qwen3-lite
    - sonnet
    - haiku
    - llama3

# Model roles map abstract roles to concrete models per provider context
# Use with: /pipeline --provider anthropic <pipeline-name>
model-roles:
  fast:
    anthropic: haiku
    openai: gpt-5-nano
    ollama-local: qwen3-lite
    ollama-cloud: gemini-3-flash-preview
  capable:
    anthropic: sonnet
    openai: gpt-5
    ollama-local: llama3
    ollama-cloud: coder
  reasoning:
    anthropic: opus
    openai: gpt-5
    ollama-local: llama3
    ollama-cloud: gpt-oss

pipelines:
  # Provider-agnostic refactoring pipeline
  # Use with: /pipeline --provider anthropic smart-refactor <file>
  #       or: /pipeline --provider openai smart-refactor <file>
  smart-refactor:
    description: Analyze, plan, implement, review
    provider: openai  # Default provider if --provider not specified
    steps:
      - name: analyze
        role: fast
        prompt: 'Analyze refactoring opportunities: {input}'
        output: analysis
      - name: plan
        role: capable
        prompt: 'Create refactoring plan based on: {analysis}'
        output: plan
      - name: implement
        role: capable
        prompt: 'Implement the plan: {plan}'
        output: implementation
      - name: review
        role: fast
        prompt: 'Quick review: {implementation}'
        output: review
    result: |-
      {implementation}

      ## Review
      {review}

  # Provider-agnostic code review pipeline
  # Use with: /pipeline --provider anthropic code-review <file>
  #       or: /pipeline --provider openai code-review <file>
  code-review:
    description: Multi-step code review using roles
    provider: openai  # Default provider if --provider not specified
    steps:
      - name: quick-scan
        role: fast
        prompt: 'Quick scan for obvious issues: {input}'
        output: quick_issues
      - name: deep-analysis
        role: capable
        prompt: 'Deep analysis of code quality, architecture, and best practices: {input}\n\nQuick scan found: {quick_issues}'
        output: analysis
      - name: suggestions
        role: fast
        prompt: 'Summarize actionable suggestions from: {analysis}'
        output: suggestions
    result: |-
      ## Code Review

      ### Quick Scan
      {quick_issues}

      ### Analysis
      {analysis}

      ### Suggestions
      {suggestions}
